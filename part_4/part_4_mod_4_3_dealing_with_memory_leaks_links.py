"""Dealing with Memory Leaks"""
# There's a ton of reasons why an application may request a lot of memory.
# Sometimes, it's what we need for the program to complete its task. Sometimes, it's caused by a part of the software
# misbehaving.

# First, let's trigger the misbehavior ourselves to see what this looks like.
# We'll use a terminal called 'uxterm' for that. open memory_leaks_0.png
# We've configured this terminal to have a really long scroll buffer.
# The scroll buffer is that nifty feature that lets us scroll up and see the things that we executed and their output.
# The contents of the buffer are kept in memory. So if we make it really long and managed to fill, it will cause our
# computer to run out of memory. With normal use, it might take ages until it happens, but if we run a command that
# keeps generating a lot of output, we could manage to fill that buffer pretty quickly. open memory_leaks_1.png

# Run:
# od -cx /dev/urandom

# This command will take the random numbers generated by the 'urandom' device and show them as both characters and
# hexadecimal numbers. Since the urandom device keeps giving more and more random numbers, it will just keep going.
# Our command is filling up the scroll buffer, making a computer require more and more memory.

# In a different terminal, let's open 'top' and check out what's going on.
# Press 'Shift-M' to order the programs by how much memory they are using.
# We see that the percentage of memory used by uxterm is going up super quickly.

# Let's stop the process, it's filling up the buffer by pressing "Ctrl-C". open memory_leaks_2.png
# With that, we stopped the command that was filling the buffer, but the terminal still has that memory allocated,
# storing all the lines in the scroll buffer.

# Let's look at the output of 'top' in a bit more detail.
# There's a bunch of different columns with data about each process.

# The column labeled RES is the dynamic memory that's preserved for the specific process.
# SHR is for memory that's shared across processes, and the one labeled VIRT lists all the virtual memory allocated for
# each process. This includes: process specific memory, shared memory, and other shared resources that are stored on
# disk but mapped into memory of the process. It's usually fine for a process to have a high value in the VIRT column.
# The one that usually indicates a problem is the RES column. open memory_leaks_3.png

# Let's close the other terminal so that it releases all the memory that it reserved.
# In this example, we saw what a program that keeps requesting more and more memory looks like.
# This was a super extreme example. Most memory leaks don't happen at the speed. It can usually take a long while until
# we notice that a program is taking more memory than it should, and it might be hard to tell the difference between
# memory that's actually needed and memory that's being wasted.
# But looking at the output of 'top' and comparing it to what it used to be awhile back is usually how any investigation
# into a memory leak starts.

# Let's look at a different example.
# We have a script that analyzes the frequency of words in web pages. This script works fine when it's just a few web
# pages, but if we try to give it all the Wikipedia contents, it starts using up all the memory.
# Let's run it first and see what happens. open memory_leaks_4.png This is running, and it will take a long while to
# finish. It's processing a huge amount of articles after all.

# While this is running, let's look at the output of 'top' in a different terminal and see what we find. open memory_leaks_5.png
# We see that there's a bunch of different 'contents_stats' processes running. That's because our script is using
# the multiprocessing techniques that we saw in an earlier video to parallelize the processing of the information and
# get the results as fast as possible. It seems like these scripts are taking a lot of memory. So let's sort it out to
# see the details. We see that the memory used by one of the processes in particular keeps growing and growing.
# open memory_leaks_6.png

# The application is processing a bunch of data and generating a dictionary with it. So it's expected that it will use
# some memory but not this much. This looks like the program is storing more than it should in memory.
# This program is pretty complex. So we could use the help of a memory profiler here to figure out what the problem is.

# Let's stop it now and use a profiler to figure out where our computer's memory is going.
# To do that, we'll need to use a simplified version of our code as profiling the memory of a multiprocess application
# is extra hard, and instead of processing all the articles, we'll just handle a few so that we can check up the memory
# consumption quickly.

# Let's open our simplified script and have a look. We'll be using a module called 'memory_profiler': from memory_profiler import profile
# This is one of the many different memory profilers available for Python. We've added this app profile label before
# the main() function definition to tell the profiler that we wanted to analyze the memory consumption of it.
# open memory_leaks_7.png

# This type of label is called a decorator, and it's used in Python to add extra behavior to functions without having
# to modify the code. In this case, the extra behavior is measuring the use of memory. The rest of the code is
# basically the same as the original one, it just uses a single process and is limited to 50 articles instead of
# the thousands of articles that the other script was going through.

# open memory_leaks_8.png
# We're running the script with the memory profiler enabled. This is just reading through 50 articles, but it takes a
# bunch of time because all that memory profiling makes our script slower. Once the program finishes, the memory
# profiler gives us information about which lines are adding or removing data from the memory used by the program.
# open memory_leaks_9.png The first column shows us the amount of memory required when each line gets executed. The
# second one shows the increase in memory for each specific line. We see here that after going through 50 articles, the
# program already took 130 megabytes, no wonder we ran out of memory when we were trying to process all the articles.

# We can see that the variables that require the most memory are article and text, with about 4 and of 3 Mb respectively.
# Those are the articles we're processing, and it's fine for them to take space while we're counting the words in the
# article. But once were done processing one article, we shouldn't keep that memory around.
# Can you spot the problem? Right at the end, the code is storing the article to keep a reference to it,
# but it's storing the whole article. If we want to keep a reference to all the articles that include a word,
# we could store the titles or the index entries, definitely not the whole contents. open memory_leaks_10.png

"""More About Managing Resources"""
# https://www.pluralsight.com/blog/tutorials/how-to-profile-memory-usage-in-python
# https://www.linuxjournal.com/content/troubleshooting-network-problems
